{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374d7ea4",
   "metadata": {},
   "source": [
    "# Streamlining Deep Learning with PyTorch Lightning ‚ö°\n",
    "\n",
    "---\n",
    "\n",
    "This notebook introduces **PyTorch Lightning (PL)**, a high-level framework that wraps PyTorch. PL is not covered in detail in Raschka's book but is an essential tool in the modern deep learning ecosystem, providing a **structured, reusable, and less verbose way** to organize the training and evaluation steps learned in Chapter 13.\n",
    "\n",
    "It demonstrates how to abstract away the boilerplate code (like moving data to GPU, managing training loops, and handling validation) into a clean, single class.\n",
    "\n",
    "### 1. The `pl.LightningModule` Paradigm üèóÔ∏è\n",
    "\n",
    "The core of the notebook is defining a custom model class that inherits from `pl.LightningModule` (e.g., `MLPClassifier`). This class organizes all the necessary PyTorch components:\n",
    "\n",
    "* **`__init__(self, ...)`:** Defines the network layers (`nn.Linear`) and metrics (like `torchmetrics.Accuracy`).\n",
    "* **`forward(self, x)`:** Defines the prediction logic (the standard forward pass).\n",
    "* **`training_step(self, batch, batch_idx)`:** Defines the logic for a single training batch, automatically handling the loss calculation, backward pass, and logging.\n",
    "* **`validation_step(self, batch, batch_idx)`:** Defines the logic for evaluation, automatically run periodically by the Trainer.\n",
    "* **`configure_optimizers(self)`:** Defines the optimizer (`optim.Adam`) and learning rate scheduler.\n",
    "\n",
    "### 2. Data Organization with `pl.DataModule` (Implicitly Demonstrated)\n",
    "\n",
    "Although not always explicitly subclassed, the notebook relies on the PyTorch Lightning structure for data management:\n",
    "\n",
    "* It uses **`torchvision.datasets.MNIST`** for data loading, splitting it into training and validation sets via `random_split`.\n",
    "* It sets up the **`DataLoader`**s for batching, which are then passed directly to the `Trainer`.\n",
    "\n",
    "### 3. The Central `pl.Trainer`\n",
    "\n",
    "PyTorch Lightning replaces the hundreds of lines of the manual training loop from Chapter 13 with a single, highly configurable `Trainer` object:\n",
    "\n",
    "* **Initialization:** The `Trainer` is initialized with essential parameters like `max_epochs`, `devices` (for GPU/CPU selection), and `logger` (for tracking results).\n",
    "* **Training Execution:** A single call to **`trainer.fit(model, train_dataloader, val_dataloader)`** executes the entire training regimen:\n",
    "    * Manages epochs, batches, and device transfers (CPU/GPU).\n",
    "    * Handles checkpointing and logging.\n",
    "    * Automatically runs validation and saves the best model.\n",
    "\n",
    "### 4. Visualization with TensorBoard üìä\n",
    "\n",
    "* The notebook leverages the built-in integration of **TensorBoard** (`%tensorboard --logdir lightning_logs/`).\n",
    "* This demonstrates how PyTorch Lightning automatically logs metrics (like train/validation loss and accuracy) to a standard directory, providing powerful visual tools for monitoring model performance and debugging without extra code.\n",
    "\n",
    "This notebook showcases how PyTorch Lightning significantly reduces complexity, making PyTorch code more scalable and easier to share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a1297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d8b298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics.classification import Accuracy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPClassifier(pl.LightningModule):\n",
    "    def __init__(self, image_shape=(1, 28, 28), hidden_units=(32, 16), lr=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Metrics\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.valid_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "        # Model\n",
    "        input_size = image_size[0] * image_size[1] * image_size[2]\n",
    "        layers = [nn.Flatten()]\n",
    "        for hidden_layer in hidden_layers:\n",
    "            layers += [nn.Linear(input_size, hidden_layer)]\n",
    "            input_size = hidden_layer\n",
    "        layers.append(nn.Linear(hidden_layers[-1], 10))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def step(self, batch, stage):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = getattr(self, f\"{stage}_acc\")(preds, y)\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "        self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"valid\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24c6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size= 64, data_path= './'):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = data_path\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        MNIST(root= self.data_path, train= True, download= True)\n",
    "        MNIST(root= self.data_path, train= False, download= True)\n",
    "        \n",
    "    def setup(self, stage= None):\n",
    "        mnist_full = MNIST(root= self.data_path, \n",
    "                           train= True, \n",
    "                           transform= self.transform, \n",
    "                           download= False)\n",
    "        self.train, self.val = random_split(mnist_full, [55000, 5000])\n",
    "        self.test = MNIST(root= self.data_path, \n",
    "                          train= False, \n",
    "                          transform= self.transform,\n",
    "                          download= False)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size= self.batch_size, shuffle= True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size= self.batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size= self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6901f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, image_size= (1, 28, 28), hidden_layers= (32, 16)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_acc = Accuracy(task= 'multiclass', num_classes= 10)\n",
    "        self.val_acc = Accuracy(task= 'multiclass', num_classes= 10)\n",
    "        self.test_acc = Accuracy(task= 'multiclass', num_classes= 10)\n",
    "        \n",
    "        input_size = image_size[0] * image_size[1] * image_size[2]\n",
    "        layers = [nn.Flatten()]\n",
    "        for hidden_layer in hidden_layers:\n",
    "            layers += [nn.Linear(input_size, hidden_layer)]\n",
    "            input_size = hidden_layer\n",
    "        layers.append(nn.Linear(hidden_layers[-1], 10))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.cross_entropy(self(x), y)\n",
    "        preds = torch.argmax(logits, dim= 1)\n",
    "        self.train_acc.update(preds, y)\n",
    "        self.log('train_loss', loss, prog_bar= True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.log('train_acc', self.train_acc.compute(), prog_bar= True)\n",
    "        self.train_acc.reset()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.cross_entropy(self(x), y)\n",
    "        preds = torch.argmax(logits, dim= 1)\n",
    "        self.val_acc.update(preds, y)\n",
    "        self.log('val_loss', loss, prog_bar= True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log('val_acc', self.val_acc.compute(), prog_bar= True)\n",
    "        self.val_acc.reset()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.cross_entropy(self(x), y)\n",
    "        preds = torch.argmax(logits, dim= 1)\n",
    "        self.test_acc.update(preds, y)\n",
    "        self.log('test_loss', loss, prog_bar= True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def on_test_epoch_end(self):\n",
    "        self.log('test_acc', self.test_acc.compute(), prog_bar= True)\n",
    "        self.test_acc.reset()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr= 0.001)\n",
    "        \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b38dc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path= './'):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        MNIST(root= self.data_path, download= True)\n",
    "    \n",
    "    def setup(self, stage= None):\n",
    "        mnist_all = MNIST(root= self.data_path, \n",
    "                          train= True, \n",
    "                          transform= self.transform, \n",
    "                          download= False)\n",
    "        self.train, self.val = random_split(mnist_all, [55000, 5000], generator= torch.Generator().manual_seed(1))\n",
    "        \n",
    "        self.test = MNIST(root= self.data_path, \n",
    "                          train= False, \n",
    "                          transform= self.transform, \n",
    "                          download= False)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size= 64, num_workers= 4, persistent_workers= True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size= 64, num_workers= 4, persistent_workers= True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size= 64, num_workers= 4, persistent_workers= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b143e9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(1)\n",
    "    data_module = MnistDataModule()\n",
    "    model = MultiLayerPerceptron()\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs= 10,\n",
    "        accelerator= 'auto',\n",
    "        devices= 'auto',\n",
    "        deterministic= True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ed48871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy | 0      | train\n",
      "1 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "2 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | model     | Sequential         | 25.8 K | train\n",
      "---------------------------------------------------------\n",
      "25.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.8 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1827320169f464bb903323e93f5c9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule= data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feb703ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e25e455b44295bad\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e25e455b44295bad\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68e6604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at ./lightning_logs/version_3/checkpoints/epoch=9-step=8600.ckpt\n",
      "C:\\Users\\98922\\anaconda3\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:366: The dirpath has changed from 'C:\\\\Users\\\\98922\\\\Documents\\\\python_scripts\\\\AI\\\\pytorch_raschka\\\\chap13\\\\lightning_logs\\\\version_3\\\\checkpoints' to 'C:\\\\Users\\\\98922\\\\Documents\\\\python_scripts\\\\AI\\\\pytorch_raschka\\\\chap13\\\\lightning_logs\\\\version_4\\\\checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy | 0      | train\n",
      "1 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "2 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | model     | Sequential         | 25.8 K | train\n",
      "---------------------------------------------------------\n",
      "25.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.8 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Restored all states from the checkpoint at ./lightning_logs/version_3/checkpoints/epoch=9-step=8600.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839596e3e3e949d9a37b18c33676fc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs= 15,\n",
    "    accelerator= 'auto',\n",
    "    devices= 'auto',\n",
    "    deterministic= True\n",
    ")\n",
    "trainer.fit(model, datamodule= data_module, ckpt_path= './lightning_logs/version_3/checkpoints/epoch=9-step=8600.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbb26feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 16496), started 0:57:34 ago. (Use '!kill 16496' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-58132d6dd4194f7f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-58132d6dd4194f7f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e5f2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
