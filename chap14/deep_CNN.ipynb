{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608f1610",
   "metadata": {},
   "source": [
    "# Foundations of Deep CNNs and Loss Functions (Chapter 14 - Initial Focus)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook marks the beginning of **Chapter 14: Classifying Images with Deep Convolutional Neural Networks (CNNs)**. It introduces the fundamental building blocks and mathematical functions necessary to shift from simple Multilayer Perceptrons (MLPs) to highly effective image processing architectures.\n",
    "\n",
    "The primary focus is on **data representation** for images and the correct **loss function** selection for classification tasks.\n",
    "\n",
    "### 1. Image Data Handling and Representation üñºÔ∏è\n",
    "\n",
    "* **Image Tensors:** Demonstrates how images are represented in PyTorch as high-dimensional Tensors, typically in the format **(Channels, Height, Width)** (C, H, W).\n",
    "* **Color Channels:** Verifies that color images (like the example `example-image.png`) have a channel dimension of **3 (RGB)**, while grayscale images (like MNIST) would have 1.\n",
    "* **Data Type:** Confirms that raw image data is initially loaded as integer types (e.g., `torch.uint8`) before being converted to floating-point numbers (0.0 to 1.0) for network input.\n",
    "\n",
    "### 2. The Core Convolutional Concept (Conceptual)\n",
    "\n",
    "Although the main `nn.Conv2d` layer implementation may be in the next notebook, this file sets the stage by:\n",
    "\n",
    "* **Introducing Kernels/Filters:** Discussing the concept of a small 2D array (the kernel) that slides over the input image to extract features like edges, corners, and textures. \n",
    "\n",
    "### 3. Mastering Loss Functions for Classification ‚öñÔ∏è\n",
    "\n",
    "This section provides a crucial technical deep-dive into selecting the correct loss function, depending on the network's output:\n",
    "\n",
    "* **Binary Classification:**\n",
    "    * **`nn.BCELoss` (Binary Cross-Entropy Loss):** Requires the network output to be **probabilities** (passed through a `torch.sigmoid` activation).\n",
    "    * **`nn.BCEWithLogitsLoss`:** This is the numerically stable, preferred alternative. It takes the **raw model output (logits)** and performs the sigmoid activation internally, which reduces numerical errors. The notebook demonstrates that both methods yield the same result when implemented correctly.\n",
    "* **Multiclass Classification:**\n",
    "    * **`nn.NLLLoss` (Negative Log Likelihood Loss):** Requires the network output to be **log-probabilities** (passed through `torch.log(torch.softmax(...))`).\n",
    "    * **`nn.CrossEntropyLoss`:** This is the standard, preferred alternative for multiclass problems. It takes the **raw model output (logits)** and performs both the **Softmax activation** and the **Log-Likelihood loss** calculation internally, providing superior numerical stability and convenience. The notebook shows that both methods yield the same result.\n",
    "\n",
    "This notebook ensures the foundation is strong‚Äîwith correct data input and numerically stable loss functions‚Äîbefore proceeding to build the complex CNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252c3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b07ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_image('example-image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab3157e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 252, 221])\n",
      "Image number of channels: 3\n",
      "Image data type: torch.uint8\n"
     ]
    }
   ],
   "source": [
    "print(f'Image shape: {img.shape}')\n",
    "print(f'Image number of channels: {img.shape[0]}')\n",
    "print(f'Image data type: {img.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa202286",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.BCELoss()\n",
    "loss = loss_func(torch.tensor([0.9]), torch.tensor([1.0]))\n",
    "l2_lambda = 0.001\n",
    "conv_layers = torch.nn.Conv2d(in_channels= 3, out_channels= 5, kernel_size= 5)\n",
    "l2_penalty = l2_lambda * sum([(p ** 2).sum() for p in conv_layers.parameters()])\n",
    "loss = loss + l2_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c988b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layers = torch.nn.Linear(10, 16)\n",
    "l2_penalty = l2_lambda * sum([(p ** 2).sum() for p in linear_layers.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c821516",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(conv_layers.parameters(), lr= 0.001, weight_decay= l2_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aff8700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss with probabilities: 0.3711\n",
      "Loss with logits: 0.3711\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([0.8])\n",
    "probs = torch.sigmoid(logits)\n",
    "target = torch.tensor([1.0])\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "bce_loss_with_logits = torch.nn.BCEWithLogitsLoss()\n",
    "print(f'Loss with probabilities: {bce_loss(probs, target):.4f}')\n",
    "print(f'Loss with logits: {bce_loss_with_logits(logits, target):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab9fbcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss with probabilities: 0.5996\n",
      "Loss with logits: 0.5996\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.5, 0.8, 2.1]])\n",
    "probs = torch.softmax(logits, dim= 1)\n",
    "target = torch.tensor([2])\n",
    "loss_with_prob = torch.nn.NLLLoss()\n",
    "loss_with_logits = torch.nn.CrossEntropyLoss()\n",
    "print(f'Loss with probabilities: {loss_with_prob(torch.log(probs), target):.4f}')\n",
    "print(f'Loss with logits: {loss_with_logits(logits, target):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62ab30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
