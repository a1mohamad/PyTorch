{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfdecd1",
   "metadata": {},
   "source": [
    "# Foundations of Self-Attention and Multi-Head Attention (Chapter 16 - Initial Focus)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook introduces the revolutionary **Self-Attention** mechanism, the core component of the Transformer architecture, marking the beginning of **Chapter 16: Transformers - Attention Beyond Recurrence**. Unlike RNNs (Chapter 15), which process sequences sequentially, Self-Attention processes all elements in parallel, determining the context and dependencies between them simultaneously.\n",
    "\n",
    "### 1. Preparing the Input for Attention ðŸ§ \n",
    "\n",
    "* **Input Embedding:** The notebook starts with a simple input sequence (a sentence represented by token indices) and uses an **`nn.Embedding`** layer to convert these indices into dense, continuous vectors. This embedding vector is the foundation of the attention calculation.\n",
    "* **Query, Key, and Value Projections (Q, K, V):** The central concept of attention is that the input embedding ($X$) is transformed into three different representations using three distinct weight matrices ($W_Q$, $W_K$, $W_V$):\n",
    "    * **Query ($Q$):** Used to score against all keys.\n",
    "    * **Key ($K$):** Used to score against the query.\n",
    "    * **Value ($V$):** The content that is summed up according to the scores (attention weights).\n",
    "* **Implementation:** The notebook manually defines and applies three separate `nn.Linear` layers to the input embeddings to obtain the $Q$, $K$, and $V$ matrices.\n",
    "\n",
    "### 2. The Scaled Dot-Product Attention Mechanism\n",
    "\n",
    "The core calculation follows the formula: $\\text{Attention}(Q, K, V) = \\text{Softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
    "\n",
    "* **Scoring ($QK^T$):** This step calculates the **raw attention scores** by taking the dot product of the Query matrix with the transpose of the Key matrix. The score indicates how relevant every word in the sequence is to every other word.\n",
    "* **Scaling:** The scores are divided by the square root of the key vector dimension ($\\sqrt{d_k}$). This is the **scaling factor** introduced to prevent the dot products from becoming too large (especially with deep networks), which can push the Softmax function into regions with tiny gradients.\n",
    "* **Softmax:** The scaled scores are passed through the **`nn.Softmax`** function. This converts the raw scores into a probability distribution (the **Attention Weights**), where all weights sum to 1.\n",
    "* **Final Output ($Z$):** The final output is calculated by multiplying the Softmax weights by the **Value** matrix. This produces the **Context Vector** ($Z$), where the representation of each word is a weighted sum of the values of all words in the sequence. \n",
    "\n",
    "### 3. Introduction to Multi-Head Attention\n",
    "\n",
    "The notebook introduces the concept of **Multi-Head Attention**â€”the idea of running several attention mechanisms in parallel:\n",
    "\n",
    "* **Heads:** Instead of one large $Q$, $K$, and $V$, the input is split into multiple smaller \"heads.\" Each head learns to focus on different aspects of the dependencies (e.g., one head for syntax, one for semantics).\n",
    "* **Implementation:** This is demonstrated by manually defining multiple projection matrices ($W_{Q_i}$, $W_{K_i}$, $W_{V_i}$) for different heads.\n",
    "* **Concatenation:** The outputs of all heads are concatenated and passed through a final linear layer to produce the final context vector.\n",
    "\n",
    "This notebook provides a detailed, step-by-step mathematical breakdown of the attention mechanism, which entirely replaces the complex sequential processing of RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ad9d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddf15293",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = torch.tensor([\n",
    "    0,\n",
    "    7,\n",
    "    1,\n",
    "    2,\n",
    "    5,\n",
    "    6,\n",
    "    4,\n",
    "    3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d5ed870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = nn.Embedding(10, 16)\n",
    "embedded_sentence = embed(sentence).detach()\n",
    "embedded_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb8c67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = torch.empty(8, 8)\n",
    "for i, x_i in enumerate(embedded_sentence):\n",
    "    for j, x_j in enumerate(embedded_sentence):\n",
    "        omega[i, j] = torch.dot(x_i, x_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c56fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_mat = embedded_sentence.matmul(embedded_sentence.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e6d2e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(omega_mat, omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14b414db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = nn.functional.softmax(omega, dim= 1)\n",
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fc2cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights.sum(dim= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e709305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.3975e-01, -4.6856e-01,  1.0311e+00, -2.8192e-01,  4.9373e-01,\n",
       "        -1.2896e-02, -2.7327e-01, -7.6358e-01,  1.3958e+00, -9.9543e-01,\n",
       "        -7.1287e-04,  1.2449e+00, -7.8077e-02,  1.2765e+00, -1.4589e+00,\n",
       "        -2.1601e+00])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1, :]\n",
    "context_vec2 = torch.zeros(x_2.shape)\n",
    "for j in range(8):\n",
    "    x_j = embedded_sentence[j, :]\n",
    "    context_vec2 += attention_weights[1, j] * x_j\n",
    "context_vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45406a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vectors = torch.matmul(attention_weights, embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00d2b11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(context_vec2, context_vectors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b18b4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "U_query = torch.rand(d, d)\n",
    "U_key = torch.rand(d, d)\n",
    "U_value = torch.rand(d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "954cb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = U_query.matmul(x_2)\n",
    "key_2 = U_key.matmul(x_2)\n",
    "value_2 = U_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4fd6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = U_key.matmul(embedded_sentence.T).T\n",
    "values = U_value.matmul(embedded_sentence.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf30144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(key_2, keys[1]))\n",
    "print(torch.allclose(value_2, values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90680b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.3667)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega_23 = query_2.dot(keys[2])\n",
    "omega_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2d23a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-25.1623,   9.3602,  14.3667,  32.1482,  53.8976,  46.6626,  -1.2131,\n",
       "        -32.9392])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omega_2 = query_2.matmul(keys.T)\n",
    "omega_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f99ee4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2317e-09, 1.2499e-05, 4.3696e-05, 3.7242e-03, 8.5596e-01, 1.4026e-01,\n",
       "        8.8897e-07, 3.1935e-10])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2 = nn.functional.softmax(omega_2 / d ** 0.5, dim= 0)\n",
    "attention_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68955ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2226, -3.4387, -4.3928, -5.2125, -1.1249, -3.3041, -1.4316, -3.2765,\n",
       "        -2.5114, -2.6105, -1.5793, -2.8433, -2.4142, -0.3998, -1.9917, -3.3499])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec2 = attention_weights_2.matmul(values)\n",
    "context_vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c8f1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "one_U_query = torch.rand(d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c40d1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 8\n",
    "multihead_U_query = torch.rand(h, d, d)\n",
    "multihead_U_key = torch.rand(h, d, d)\n",
    "multihead_U_value = torch.rand(h, d, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a3416a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16])\n",
      "tensor([-1.1907, -1.8279, -1.5237,  0.2820, -1.6944, -1.6440, -0.7748, -1.2830,\n",
      "        -1.6806, -0.1230, -0.4647, -0.0889, -2.0839, -2.7138, -0.7688, -1.9872])\n"
     ]
    }
   ],
   "source": [
    "multihead_query_2 = multihead_U_query.matmul(x_2)\n",
    "multihead_key_2 = multihead_U_key.matmul(x_2)\n",
    "multihead_value_2 = multihead_U_value.matmul(x_2)\n",
    "print(multihead_query_2.shape)\n",
    "print(multihead_query_2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "296b44bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_input = embedded_sentence.T.repeat(8, 1, 1)\n",
    "stacked_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f755dcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 8])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_keys = torch.bmm(multihead_U_key, stacked_input)\n",
    "multihead_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ff3a29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 16])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_keys = multihead_keys.permute(0, 2, 1)\n",
    "multihead_keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "411493eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0533, -0.2590, -0.5376, -0.8360,  0.1815, -1.0017, -0.9257, -1.4889,\n",
       "        -1.6172, -0.2682,  2.2755, -0.0882, -0.1427,  0.3652, -0.4133, -1.3387])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_keys[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c694ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 16])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_values = multihead_U_value.bmm(stacked_input).permute(0, 2, 1)\n",
    "multihead_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fe07a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_z_2 = torch.rand(8, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6a971ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(8*16, 16)\n",
    "context_vector_2 = linear(multihead_z_2.flatten())\n",
    "context_vector_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2bb427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
